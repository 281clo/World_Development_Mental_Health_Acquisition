{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "resident-mechanism",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "marine-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import plotly as py\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import download_plotlyjs, plot, iplot\n",
    "import sqlite3\n",
    "import re\n",
    "import Code.Preparation as prep\n",
    "import itertools\n",
    "import warnings\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-cable",
   "metadata": {},
   "source": [
    "### Clean and combine happiness reports dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-robert",
   "metadata": {},
   "source": [
    "Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "arctic-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2021 = pd.read_csv(prep.path('happy/2021.csv'))\n",
    "df2021['Year'] = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nuclear-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhappy = pd.read_csv(prep.path('happy/world-happiness-report.csv'))\n",
    "RateDf = pd.read_csv(prep.path('sucide.csv'))\n",
    "RateDf = RateDf.rename(columns={'country': 'Country'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-incident",
   "metadata": {},
   "source": [
    "Change names to match corresponding columns and merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "color-venezuela",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2021 = df2021[['Country name','Year', 'Ladder score','Social support','Healthy life expectancy','Logged GDP per capita','Freedom to make life choices','Generosity','Perceptions of corruption']]\n",
    "df2021 = df2021.rename(columns={'Year': 'year', 'Ladder score': 'Life Ladder', 'Healthy life expectancy': 'Healthy life expectancy at birth', 'Logged GDP per capita': 'Log GDP per capita', })\n",
    "dfhappy = dfhappy.merge(df2021, how='outer').drop(columns=['Positive affect', 'Negative affect'])\n",
    "dfhappy = dfhappy.rename(columns={'Country name': 'Country'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-salon",
   "metadata": {},
   "source": [
    "Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "explicit-maple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country                               0\n",
       "year                                  0\n",
       "Life Ladder                           0\n",
       "Log GDP per capita                   36\n",
       "Social support                       13\n",
       "Healthy life expectancy at birth     55\n",
       "Freedom to make life choices         32\n",
       "Generosity                           89\n",
       "Perceptions of corruption           110\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfhappy.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-gather",
   "metadata": {},
   "source": [
    "Interpolate null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "artificial-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhappy = dfhappy.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-alexander",
   "metadata": {},
   "source": [
    "Save data to csv for modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acquired-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset to csv\n",
    "dfhappy.to_csv('Data/CleanedHappy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-feature",
   "metadata": {},
   "source": [
    "### World Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rotary-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf = pd.read_csv(prep.path('WDI/WDIData.csv'))\n",
    "countrydf = pd.read_csv(prep.path('WDI/WDICountry.csv'))\n",
    "df = pd.read_csv(prep.path('World_Development/Indicators.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "framed-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Indicator_array =  df[['IndicatorName','IndicatorCode']].drop_duplicates().values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-transaction",
   "metadata": {},
   "source": [
    "Search tool for relevent features that could have a impact on suicides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "consecutive-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_indicators = []\n",
    "unique_indicator_codes = []\n",
    "for ele in Indicator_array:\n",
    "    indicator = ele[0]\n",
    "    indicator_code = ele[1].strip()\n",
    "    if indicator_code not in unique_indicator_codes:\n",
    "        # delete , ( ) from the IndicatorNames\n",
    "        new_indicator = re.sub('[,()]',\"\",indicator).lower()\n",
    "        # replace - with \"to\" and make all words into lower case\n",
    "        new_indicator = re.sub('-',\" to \",new_indicator).lower()\n",
    "        modified_indicators.append([new_indicator,indicator_code])\n",
    "        unique_indicator_codes.append(indicator_code)\n",
    "\n",
    "Indicators = pd.DataFrame(modified_indicators,columns=['IndicatorName','IndicatorCode'])\n",
    "Indicators = Indicators.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dental-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word_dict = {}\n",
    "key_word_dict['Food'] = ['food','grain','nutrition','calories']\n",
    "key_word_dict['Foreign'] = ['foreign']\n",
    "key_word_dict['Health'] = ['health','desease','hospital','mortality','doctor', 'mental']\n",
    "key_word_dict['Economy'] = ['income','gdp','gni','deficit','budget','market','stock','bond','infrastructure', 'investment']\n",
    "key_word_dict['Education'] = ['education','literacy', 'school', 'college']\n",
    "key_word_dict['Energy'] = ['fuel','energy','power','emission','electric','electricity', 'water']\n",
    "key_word_dict['Employment'] =['employed','employment','umemployed','unemployment']\n",
    "key_word_dict['Rural'] = ['rural','village']\n",
    "key_word_dict['Urban'] = ['urban','city']\n",
    "key_word_dict['Social Programs'] = ['social', 'welfare']\n",
    "key_word_dict['Tech'] = ['technology', 'tech', 'phone', 'mobile', 'broadband', 'cable', 'telephone']\n",
    "key_word_dict['Trade'] = ['trade','import','export','good','shipping','shipment']\n",
    "key_word_dict['Water'] = ['water', 'sanitation', 'sanitary']\n",
    "key_word_dict['Access'] = ['access']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "quick-suspect",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['social contributions % of revenue' 'GC.REV.SOCL.ZS']\n",
      "['social contributions current lcu' 'GC.REV.SOCL.CN']\n",
      "['adequacy of social insurance programs % of total welfare of beneficiary households'\n",
      " 'per_si_allsi.adq_pop_tot']\n",
      "['adequacy of social protection and labor programs % of total welfare of beneficiary households'\n",
      " 'per_allsp.adq_pop_tot']\n",
      "['adequacy of unemployment benefits and almp % of total welfare of beneficiary households'\n",
      " 'per_lm_alllm.adq_pop_tot']\n",
      "['benefits incidence in poorest quintile %  to  all social insurance'\n",
      " 'per_si_allsi.ben_q1_tot']\n",
      "['benefits incidence in poorest quintile %  to all social protection and labor'\n",
      " 'per_allsp.ben_q1_tot']\n",
      "['coverage %  to  all social insurance' 'per_si_allsi.cov_pop_tot']\n",
      "['coverage %  to all social protection and labor' 'per_allsp.cov_pop_tot']\n",
      "['coverage %  to  all social assistance' 'per_sa_allsa.cov_pop_tot']\n",
      "['adequacy of social safety net programs % of total welfare of beneficiary households'\n",
      " 'per_sa_allsa.adq_pop_tot']\n",
      "['benefits incidence in poorest quintile %  to  all social assistance'\n",
      " 'per_sa_allsa.ben_q1_tot']\n",
      "['cpia policies for social inclusion/equity cluster average 1=low to 6=high'\n",
      " 'IQ.CPA.SOCI.XQ']\n",
      "['cpia social protection rating 1=low to 6=high' 'IQ.CPA.PROT.XQ']\n"
     ]
    }
   ],
   "source": [
    "feature = 'Social Programs'\n",
    "for indicator in Indicators.values:\n",
    "    for w in key_word_dict[feature]:\n",
    "        word_list = indicator[0].split()\n",
    "        if w in word_list or w+'s' in word_list:\n",
    "            # Uncomment this line to print the indicators explicitely\n",
    "            print(indicator)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "traditional-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "worlddf = pd.DataFrame(datadf.groupby(['Country Name','Indicator Name']).mean().stack())\n",
    "worlddf = worlddf.reset_index()\n",
    "worlddf = worlddf.rename(columns={0: 'Value', 'level_2': 'year', 'Country Name': 'Country', 'Indicator Name': 'IndicatorName'})\n",
    "worlddf = worlddf[worlddf.year >= '1985']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stuffed-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "worlddf.to_csv('Data/WorldDf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-skating",
   "metadata": {},
   "source": [
    "\n",
    "We start off by creating categorical variables for our suicide dataset and ordering our data frames by country and year in the index. We then drop all the years in our categorical dataset and only keep the most recent year to combine the categorical data frame with our continuous variables data frame which in turn gives us one clean processed data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-villa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "administrative-insertion",
   "metadata": {},
   "source": [
    "***\n",
    "### Model Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-petersburg",
   "metadata": {},
   "source": [
    "\n",
    "We start off by creating categorical variables for our suicide dataset and ordering our data frames by country and year in the index. We then drop all the years in our categorical dataset and only keep the most recent year to combine the categorical data frame with our continuous variables data frame which in turn gives us one clean processed data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "boring-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy wiht only categorical variables\n",
    "RateCat = RateDf.copy().set_index(['Country', 'year'])[['sex', 'age', 'generation']]\n",
    "\n",
    "# Initiate label encoder and apply to our categorical columns.\n",
    "le = LabelEncoder()\n",
    "RateCat['sex'] = le.fit_transform(RateCat['sex'])\n",
    "RateCat['age'] = le.fit_transform(RateCat['age'])\n",
    "RateCat['generation'] = le.fit_transform(RateCat['generation'])\n",
    "RateCat.reset_index(inplace=True)\n",
    "\n",
    "# Drop all but keep the last categorical data for each year(each year has 12 different categories for data so only keep the last for each)\n",
    "RateCat.drop_duplicates(subset=['Country', 'year'], keep='last', inplace=True)\n",
    "\n",
    "#Create dataframe with continuous variables and drop population as it's not relevent and could cause multicollenuarity issues. \n",
    "RateCon = RateDf.copy().groupby(['Country', 'year']).mean().drop(columns=['population', 'HDI for year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "recognized-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes on country and year as our index. \n",
    "RateCon = RateCon.merge(RateCat, how='outer', on=['Country', 'year']).groupby(['Country', 'year']).mean().astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-triple",
   "metadata": {},
   "source": [
    "Our world dataset does not have a target variable, only features to use as predictors for either suicide rates or happiness scores. I've manually gone through over a thousand features and tried to find only relevant features to our business problem and didn't have too many missing values.\n",
    "\n",
    "We iterate through the dataset and create a temp data frame out of a feature then combine them all into one under the same index country and year while printing a preview of the feature mean for the world. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "proud-health",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urban population growth (annual %)    2.37697\n",
      "dtype: float64\n",
      "Rural population growth (annual %)    0.480022\n",
      "dtype: float64\n",
      "Mobile cellular subscriptions (per 100 people)    38.65041\n",
      "dtype: float64\n",
      "Fixed broadband subscriptions (per 100 people)    8.618271\n",
      "dtype: float64\n",
      "Foreign direct investment, net inflows (% of GDP)    4.055229\n",
      "dtype: float64\n",
      "GNI per capita, Atlas method (current US$)    8883.122807\n",
      "dtype: float64\n",
      "Primary education, duration (years)    5.699107\n",
      "dtype: float64\n",
      "Inflation, consumer prices (annual %)    25.482019\n",
      "dtype: float64\n",
      "Access to electricity (% of population)    75.036003\n",
      "dtype: float64\n",
      "People using at least basic drinking water services (% of population)    84.189864\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "features = ['Urban population growth (annual %)', 'Rural population growth (annual %)', 'Mobile cellular subscriptions (per 100 people)',\n",
    "            'Fixed broadband subscriptions (per 100 people)', 'Foreign direct investment, net inflows (% of GDP)', 'GNI per capita, Atlas method (current US$)', 'Primary education, duration (years)', \n",
    "           'Inflation, consumer prices (annual %)', 'Access to electricity (% of population)',\n",
    "           'People using at least basic drinking water services (% of population)']\n",
    "\n",
    "def get_world_df(features):\n",
    "    \n",
    "    listi = []\n",
    "    \n",
    "    for name in features:\n",
    "        name = worlddf[worlddf.IndicatorName == name].drop(columns='IndicatorName').groupby(['Country', 'year']).mean().rename(columns={'Value': name})\n",
    "        print(name.mean())\n",
    "        listi.append(name)\n",
    "    return listi\n",
    "world = get_world_df(features)\n",
    "\n",
    "World_Over = pd.concat(world).groupby(['Country', 'year']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-damage",
   "metadata": {},
   "source": [
    "***\n",
    "Our last dataset with happiness features and our happiness score target('Life Ladder'). We set the same index for our data to be able to merge in the right locations then merge it with our suicide dataset. Finally we merge that dataset with the world features dataset to create one cohesive data frame dropping any values that are missing. Doing this will remove some data and/or years but we will be left with only valid data from all 3 data frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "increased-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "RateCon.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "built-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "RateCon.year = RateCon.year.astype(str)\n",
    "dfhappy.year = dfhappy.year.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "clean-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhappy = dfhappy.groupby(['Country', 'year']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "continued-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "HappyRate = dfhappy.merge(RateCon, on=['Country', 'year']).groupby(['Country', 'year']).mean().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "realistic-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "AllThree = World_Over.merge(HappyRate, on=['Country', 'year']).groupby(['Country', 'year']).mean().dropna() #.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adjacent-questionnaire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 519 entries, ('Albania', '2007') to ('Uruguay', '2015')\n",
      "Data columns (total 23 columns):\n",
      " #   Column                                                                 Non-Null Count  Dtype  \n",
      "---  ------                                                                 --------------  -----  \n",
      " 0   Urban population growth (annual %)                                     519 non-null    float64\n",
      " 1   Rural population growth (annual %)                                     519 non-null    float64\n",
      " 2   Mobile cellular subscriptions (per 100 people)                         519 non-null    float64\n",
      " 3   Fixed broadband subscriptions (per 100 people)                         519 non-null    float64\n",
      " 4   Foreign direct investment, net inflows (% of GDP)                      519 non-null    float64\n",
      " 5   GNI per capita, Atlas method (current US$)                             519 non-null    float64\n",
      " 6   Primary education, duration (years)                                    519 non-null    float64\n",
      " 7   Inflation, consumer prices (annual %)                                  519 non-null    float64\n",
      " 8   Access to electricity (% of population)                                519 non-null    float64\n",
      " 9   People using at least basic drinking water services (% of population)  519 non-null    float64\n",
      " 10  Life Ladder                                                            519 non-null    float64\n",
      " 11  Log GDP per capita                                                     519 non-null    float64\n",
      " 12  Social support                                                         519 non-null    float64\n",
      " 13  Healthy life expectancy at birth                                       519 non-null    float64\n",
      " 14  Freedom to make life choices                                           519 non-null    float64\n",
      " 15  Generosity                                                             519 non-null    float64\n",
      " 16  Perceptions of corruption                                              519 non-null    float64\n",
      " 17  suicides_no                                                            519 non-null    float64\n",
      " 18  suicides/100k pop                                                      519 non-null    float64\n",
      " 19  gdp_per_capita ($)                                                     519 non-null    float64\n",
      " 20  sex                                                                    519 non-null    float64\n",
      " 21  age                                                                    519 non-null    float64\n",
      " 22  generation                                                             519 non-null    float64\n",
      "dtypes: float64(23)\n",
      "memory usage: 97.9+ KB\n"
     ]
    }
   ],
   "source": [
    "AllThree.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "painted-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "AllThree.to_csv('Data/Combined_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-mount",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
