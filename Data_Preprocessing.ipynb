{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "saving-memory",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "controlling-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import plotly as py\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import download_plotlyjs, plot, iplot\n",
    "import sqlite3\n",
    "import Code.Preparation as prep\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import itertools\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import acf, pacf, adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-clock",
   "metadata": {},
   "source": [
    "### Clean and combine happiness reports dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-occasion",
   "metadata": {},
   "source": [
    "Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "macro-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2021 = pd.read_csv(prep.path('happy/2021.csv'))\n",
    "df2021['Year'] = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "welcome-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhappy = pd.read_csv(prep.path('happy/world-happiness-report.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-church",
   "metadata": {},
   "source": [
    "Change names to match corresponding columns and merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "motivated-uncle",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2021 = df2021[['Country name','Year', 'Ladder score','Social support','Healthy life expectancy','Logged GDP per capita','Freedom to make life choices','Generosity','Perceptions of corruption']]\n",
    "df2021 = df2021.rename(columns={'Year': 'year', 'Ladder score': 'Life Ladder', 'Healthy life expectancy': 'Healthy life expectancy at birth', 'Logged GDP per capita': 'Log GDP per capita'})\n",
    "dfhappy = dfhappy.merge(df2021, how='outer').drop(columns=['Positive affect', 'Negative affect'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-invite",
   "metadata": {},
   "source": [
    "Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abstract-russell",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhappy = dfhappy.rename(columns={'Country name': 'Country'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-operation",
   "metadata": {},
   "source": [
    "Interpolate null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sweet-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhappy = dfhappy.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-spanish",
   "metadata": {},
   "source": [
    "Save data to csv for modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "possible-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset to csv\n",
    "dfhappy.to_csv('Data/CleanedHappy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-karaoke",
   "metadata": {},
   "source": [
    "### World Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "phantom-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf = pd.read_csv(prep.path('WDI/WDIData.csv'))\n",
    "countrydf = pd.read_csv(prep.path('WDI/WDICountry.csv'))\n",
    "df = pd.read_csv(prep.path('World_Development/Indicators.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fossil-experience",
   "metadata": {},
   "outputs": [],
   "source": [
    "Indicator_array =  df[['IndicatorName','IndicatorCode']].drop_duplicates().values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-velvet",
   "metadata": {},
   "source": [
    "Search tool for relevent features that could have a impact on suicides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "postal-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_indicators = []\n",
    "unique_indicator_codes = []\n",
    "for ele in Indicator_array:\n",
    "    indicator = ele[0]\n",
    "    indicator_code = ele[1].strip()\n",
    "    if indicator_code not in unique_indicator_codes:\n",
    "        # delete , ( ) from the IndicatorNames\n",
    "        new_indicator = re.sub('[,()]',\"\",indicator).lower()\n",
    "        # replace - with \"to\" and make all words into lower case\n",
    "        new_indicator = re.sub('-',\" to \",new_indicator).lower()\n",
    "        modified_indicators.append([new_indicator,indicator_code])\n",
    "        unique_indicator_codes.append(indicator_code)\n",
    "\n",
    "Indicators = pd.DataFrame(modified_indicators,columns=['IndicatorName','IndicatorCode'])\n",
    "Indicators = Indicators.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fifth-parcel",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word_dict = {}\n",
    "key_word_dict['Food'] = ['food','grain','nutrition','calories']\n",
    "key_word_dict['Foreign'] = ['foreign']\n",
    "key_word_dict['Health'] = ['health','desease','hospital','mortality','doctor', 'mental']\n",
    "key_word_dict['Economy'] = ['income','gdp','gni','deficit','budget','market','stock','bond','infrastructure', 'investment']\n",
    "key_word_dict['Education'] = ['education','literacy', 'school', 'college']\n",
    "key_word_dict['Energy'] = ['fuel','energy','power','emission','electric','electricity', 'water']\n",
    "key_word_dict['Employment'] =['employed','employment','umemployed','unemployment']\n",
    "key_word_dict['Rural'] = ['rural','village']\n",
    "key_word_dict['Urban'] = ['urban','city']\n",
    "key_word_dict['Social Programs'] = ['social', 'welfare']\n",
    "key_word_dict['Tech'] = ['technology', 'tech', 'phone', 'mobile', 'broadband', 'cable', 'telephone']\n",
    "key_word_dict['Trade'] = ['trade','import','export','good','shipping','shipment']\n",
    "key_word_dict['Water'] = ['water', 'sanitation', 'sanitary']\n",
    "key_word_dict['Access'] = ['access']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adult-journal",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['social contributions % of revenue' 'GC.REV.SOCL.ZS']\n",
      "['social contributions current lcu' 'GC.REV.SOCL.CN']\n",
      "['adequacy of social insurance programs % of total welfare of beneficiary households'\n",
      " 'per_si_allsi.adq_pop_tot']\n",
      "['adequacy of social protection and labor programs % of total welfare of beneficiary households'\n",
      " 'per_allsp.adq_pop_tot']\n",
      "['adequacy of unemployment benefits and almp % of total welfare of beneficiary households'\n",
      " 'per_lm_alllm.adq_pop_tot']\n",
      "['benefits incidence in poorest quintile %  to  all social insurance'\n",
      " 'per_si_allsi.ben_q1_tot']\n",
      "['benefits incidence in poorest quintile %  to all social protection and labor'\n",
      " 'per_allsp.ben_q1_tot']\n",
      "['coverage %  to  all social insurance' 'per_si_allsi.cov_pop_tot']\n",
      "['coverage %  to all social protection and labor' 'per_allsp.cov_pop_tot']\n",
      "['coverage %  to  all social assistance' 'per_sa_allsa.cov_pop_tot']\n",
      "['adequacy of social safety net programs % of total welfare of beneficiary households'\n",
      " 'per_sa_allsa.adq_pop_tot']\n",
      "['benefits incidence in poorest quintile %  to  all social assistance'\n",
      " 'per_sa_allsa.ben_q1_tot']\n",
      "['cpia policies for social inclusion/equity cluster average 1=low to 6=high'\n",
      " 'IQ.CPA.SOCI.XQ']\n",
      "['cpia social protection rating 1=low to 6=high' 'IQ.CPA.PROT.XQ']\n"
     ]
    }
   ],
   "source": [
    "feature = 'Social Programs'\n",
    "for indicator in Indicators.values:\n",
    "    for w in key_word_dict[feature]:\n",
    "        word_list = indicator[0].split()\n",
    "        if w in word_list or w+'s' in word_list:\n",
    "            # Uncomment this line to print the indicators explicitely\n",
    "            print(indicator)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "incomplete-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "worlddf = pd.DataFrame(datadf.groupby(['Country Name','Indicator Name']).mean().stack())\n",
    "worlddf = worlddf.reset_index()\n",
    "worlddf = worlddf.rename(columns={0: 'Value', 'level_2': 'year', 'Country Name': 'Country', 'Indicator Name': 'IndicatorName'})\n",
    "worlddf = worlddf[worlddf.year >= '1985']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "healthy-hearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "worlddf.to_csv('Data/WorldDf.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
